{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IFT870 - Examen intratrimestriel\n",
        "\n",
        "Auteur : Aur\u00e9lien Vauthier (19 126 456)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from difflib import SequenceMatcher\n",
        "from tqdm import tqdm\n",
        "\n",
        "# extract data\n",
        "journal = pd.read_csv(\"api_journal11-13-17.csv\", encoding=\"latin1\")\n",
        "price = pd.read_csv(\"api_price11-13-17.csv\", index_col=0)\n",
        "influence = pd.read_csv(\"estimated-article-influence-scores-2015.csv\", index_col=0)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 1 : Exploration-Description\n",
        "\n",
        "*Pr\u00e9senter une description de chacun des attributs des 3 tables, avec des graphiques\n",
        "pour la visualisation des statistiques descriptives au besoin.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Table `journal`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# show the first values\n",
        "journal.head()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous pouvons d\u00e9j\u00e0 observer les colonnes suivantes et imaginer une petite description : \n",
        "- **issn** (valeur num\u00e9rique) : ([International Standard Serial Number](https://fr.wikipedia.org/wiki/International_Standard_Serial_Number)),\n",
        "il s'agit d'un num\u00e9ro permettant d'identifier une s\u00e9rie de publication de fa\u00e7on unique.\n",
        "- **journal_name** (valeur cat\u00e9gorique) : Le nom du journal\n",
        "- **pub_name** (valeur cat\u00e9gorique) : Le nom de l'\u00e9diteur\n",
        "- **is_hybrid** (valeur bool\u00e9enne) : (D'apr\u00e8s le site [FlourishOA](http://flourishoa.org/about#type)) Permet de savoir\n",
        "si le journal est hybride. C'est-\u00e0-dire, si le journal est \u00e0 abonnement avec certains articles en acc\u00e8s libre.\n",
        "- **category** (valeur cat\u00e9gorique) : La liste des cat\u00e9gories de la revue scientifique.\n",
        "- **url** (valeur cat\u00e9gorique) : L'adresse web de la page d'acceuil du journal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#  Compute ratio of N/A values\n",
        "(journal.isna().sum() / journal.shape[0]) * 100"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous pouvons remarquer que les colonnes `pub_name`, `category` et `url` poss\u00e8dent des donn\u00e9es manquantes. En particulier\n",
        "`category` et `url` qui ont environs 50% de donn\u00e9es manquantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute ratio of unique values\n",
        "print(f\"Ratio de valeurs uniques pour l'index : {len(np.unique(journal.index)) / journal.shape[0]:.0%}\")\n",
        "print(f\"Ratio de valeurs uniques pour issn : {journal['issn'].nunique() / journal.shape[0]:.0%}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "L'index et les ISSN sont bien uniques.\n",
        "\n",
        "La colonne `journal_name` ne semble pas avoir de probl\u00e8me mis \u00e0 part quelques donn\u00e9es dupliqu\u00e9es."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# sort and print the 10 biggest publishers\n",
        "pub, count = np.unique(journal[\"pub_name\"].dropna(), return_counts=True)\n",
        "print(\"Nombre de revue par \u00e9diteur :\")\n",
        "for pub, count in sorted(zip(pub.tolist(), count.tolist()), key=lambda x: x[1], reverse=True)[:10]:\n",
        "    print(f\"\\t- {pub} : {count} ({count/journal.shape[0]:.2%})\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On peut voir qu'il existe de gros \u00e9diteurs, en particulier `Springer` qui publie 14.3% des revues scientifiques. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# convert to bool values\n",
        "journal[\"is_hybrid\"] = journal[\"is_hybrid\"].astype(bool)\n",
        "print(f\"Ratio de revues hybrides : {journal['is_hybrid'].sum() / journal.shape[0]:.2%}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On peut voir qu'il existe de gros \u00e9diteurs, en particulier `Springer` qui publie 14.3% des revues scientifiques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "journal[\"category\"][11065:11070]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comme on peut le voir sur l'exemple ci-dessus, certaines revues poss\u00e8dent plusieurs cat\u00e9gorie qui peuvent \u00eatre s\u00e9prarer\n",
        "par plusieurs caract\u00e8res comme `|`, `.` et `and`.\n",
        "\n",
        "Finalement, pour la colonne `url`, il y a une grande partie de donn\u00e9es manquantes mais "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Table `price`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# show the first values\n",
        "price.head()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous pouvons d\u00e9j\u00e0 observer les colonnes suivantes et imaginer une petite description :\n",
        "- **price** (valeur continue) : Le prix de l'ACP (Article Publication Charge)\n",
        "- **date_stamp** (valeur temporelle) : Horodatage repr\u00e9sentant la date de cr\u00e9ation de l'entr\u00e9e.\n",
        "- **journal_id** (valeur cat\u00e9gorique) : Il s'agit de l'ISSN du journal\n",
        "- **influence_id** (valeur cat\u00e9gorique) : On pourrait supposer qu'il s'agit d'un lien vers les lignes de la table\n",
        "`influence` mais la majorit\u00e9 des id situ\u00e9s dans cette colonne sont sup\u00e9rieurs au nombre de lignes que poss\u00e8de la table\n",
        "`influence` ce qui consititue alors des valeurs ab\u00e9rantes.\n",
        "- **url** (valeur cat\u00e9gorique) : L'adresse web de la revue vers la page d'informations pour les auteurs.\n",
        "- **license** (valeur cat\u00e9gorique) : Valeur num\u00e9rique repr\u00e9sentant une lisence (nous n'avons pas d'information sur la\n",
        "correspondance entre les valeurs num\u00e9riques et les diff\u00e9rentes lisences qui existent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#  Compute ratio of N/A values\n",
        "(price.isna().sum() / price.shape[0]) * 100"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous pouvons remarquer que les colonnes `influence_id`, `url` et `license` poss\u00e8dent presque uniquement des donn\u00e9es\n",
        "manquantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def show_continuous_col_stats(df, column):\n",
        "    print(f\"Statistiques de la colonne {column} :\")\n",
        "    print(f\"- min : {df[column].min():.2f}\")\n",
        "    print(f\"- max : {df[column].max():.2f}\")\n",
        "    print(f\"- moyenne : {df[column].mean():.2f}\")\n",
        "    print(f\"- varience : {df[column].var():.2f}\")\n",
        "    print(f\"- mode : {df[column].mode()[0]:.2f}\")\n",
        "    sns.distplot(df[column].dropna())\n",
        "\n",
        "show_continuous_col_stats(price, \"price\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On remarque sur le graphique 4 groupes de prix des journaux. Un premier \u00e0 0, un deuxi\u00e8me entre 100 et 2900 environ, un\n",
        "troisi\u00e8me autour de la valeur 3000 et finalement un dernier groupe au-dessus de 3100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "price[\"date_stamp\"] = pd.to_datetime(price[\"date_stamp\"], format=\"%Y-%m-%d\")\n",
        "groupedPrice = price[\"date_stamp\"].groupby(price[\"date_stamp\"].dt.year, sort=False)\n",
        "years, years_count = [], []\n",
        "for year in groupedPrice:\n",
        "    years.append(year[0])\n",
        "    years_count.append(year[1].shape[0])\n",
        "\n",
        "plt.hist(years, bins=len(years), weights=years_count)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On note sur le graphique que la plupart des donn\u00e9es ont \u00e9t\u00e9 ajout\u00e9 en 2016 et 2017, une autre partie fut ajout\u00e9 en 2012\n",
        "et 2013. La majorit\u00e9 des donn\u00e9es est donc assez r\u00e9cente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def multicolumn_duplicate_ratio(df, columns):\n",
        "    flatten_array = df[columns].values.ravel('K')\n",
        "    n_unique = len(pd.unique(flatten_array))\n",
        "    return n_unique / df.shape[0]\n",
        "\n",
        "\n",
        "# Compute ratio of unique values\n",
        "print(f\"Ratio de valeurs uniques pour journal_id : {price['journal_id'].nunique() / price.shape[0]:.0%}\")\n",
        "print(f\"Ratio de valeurs uniques pour (journal_id, date_stamp) : {multicolumn_duplicate_ratio(price, ['date_stamp', 'journal_id']):.0%}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Contrairement \u00e0 la table `journal` il existe plusieurs duplicatas des ISSN, en effet, certaines revues scientifiques\n",
        "ont eu des mise \u00e0 jours de leurs informations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# show ratio of incoherent values\n",
        "print(f\"Ratio de valeurs incoh\u00e9rentes pour influence_id : {1 - (price['influence_id'] <= influence.index[-1]).sum() / price.shape[0]:.2%}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La quasi-totalit\u00e9 des valeurs de `influence_id` sont soit manquantes soit ont une valeur sup\u00e9rieur \u00e0 la valeur maximal\n",
        "des id de la table `influence`. Cette colonne ne semble donc pas \u00eatre utile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Valeur(s) ab\u00e9rente(s) pour la colonne url :\")\n",
        "incoherent_influence_url = price[~price[\"url\"].str.startswith(\"http\", na=True)]\n",
        "for index, row in incoherent_influence_url.iterrows():\n",
        "    print(f\"{index} : {row['url']}\")\n",
        "\n",
        "# remove incoherent values\n",
        "for index in incoherent_influence_url.index:\n",
        "    price.at[index, \"url\"] = np.NaN"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bien qu'on ne retrouve qu'une seule valeur ab\u00e9rante, la majorit\u00e9 des valeurs reste manquente. Cela nuit donc fortement \u00e0\n",
        "l'inter\u00eat de cette colonne."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "licenses, licenses_count = np.unique(price[\"license\"].dropna(), return_counts=True)\n",
        "plt.hist(licenses, bins=len(licenses), weights=licenses_count)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comme nous pouvons le voir sur l'histogramme, la lisence 2 est majoritairement utilis\u00e9e, on retrouve ensuite les\n",
        "lisences 10, 4 et 6. Cependant, ne pouvant faire l'equivalence entre ces num\u00e9ros et le nom des licenses (ou groupes de\n",
        "lisences), les informations de cette colonne ne sont pas pertinentes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Table `influence`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# show the first values\n",
        "influence.head()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous pouvons d\u00e9j\u00e0 observer les colonnes suivantes et imaginer une petite description :\n",
        "- **journal_name** (valeur cat\u00e9gorique) : Le nom du journal.\n",
        "- **issn** (valeur cat\u00e9gorique) : L'ISSN du journal.\n",
        "- **citation_count_sum** (valeur continue) : Le nombre de citation du journal.\n",
        "- **paper_count_sum** (valeur continue) : Le nombre d'articles scientifiques du journal.\n",
        "- **avg_cites_per_paper** (valeur continue) : La moyenne du nombre de citation par article du journal.\n",
        "- **proj_ai** (valeur continue) : Le score d'influence associ\u00e9 \u00e0 la moyenne des citations.\n",
        "- **proj_ai_year** (valeur temporelle) : La date associ\u00e9 au calcul du score d'influence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#  Compute ratio of N/A values\n",
        "(influence.isna().sum() / influence.shape[0]) * 100"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il n'y a presque aucune donn\u00e9es manquantes dans la table `influence`. De plus, les quatres seules colonnes en poss\u00e9dant\n",
        "un peu, `citation_count_sum`, `paper_count_sum`, `avg_cites_per_paper` et `proj_ai`, ont exactement le m\u00eame nombre de\n",
        "donn\u00e9es manquantes : 0.36%.\n",
        "\n",
        "La colonne `journal_name` ne semble pas avoir de probl\u00e8me mis \u00e0 part quelques donn\u00e9es dupliqu\u00e9es."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute ratio of unique values\n",
        "print(f\"Ratio de valeurs uniques pour l'index : {len(np.unique(influence.index)) / influence.shape[0]:.0%}\")\n",
        "print(f\"Ratio de valeurs uniques pour issn : {influence['issn'].nunique() / influence.shape[0]:.0%}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "L'index et les ISSN sont bien uniques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "show_continuous_col_stats(influence, \"citation_count_sum\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On peut noter un tr\u00e8s grande dispertion des valeurs du nombre de citations qui peut faire pense \u00e0 une distribution de\n",
        "Poisson. De nombreux journaux n'ont pas beaucoup de citation (environs 636) alors que certains journaux se dispersent\n",
        "entre des valeurs de 10 000 \u00e0 430 000 citations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "show_continuous_col_stats(influence, \"avg_cites_per_paper\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "L\u00e0 encore la similarit\u00e9 avec la loi de Poisson est visible mais cette fois-ci la dispersion des donn\u00e9es est bien moins\n",
        "pr\u00e9sente. On note tout de m\u00eame un pic autour de la valeur 1.75 et des valeurs allant jusqu'\u00e0 27. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "show_continuous_col_stats(influence, \"proj_ai\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cette colonne \u00e9tant le r\u00e9sultat d'un rapport entre les deux derni\u00e8res colonnes, il n'est pas tr\u00e8s surprenant d'observer\n",
        "une derni\u00e8re fois la Loi de Poisson avec un mode autour de la valeur 0.4 et une dispertion jusqu'\u00e0 11."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Liste des valeurs uniques de proj_ai_year :\")\n",
        "for year in influence[\"proj_ai_year\"].unique():\n",
        "    print(f\"\\t- {year}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Surprenemment, nous pouvons noter que seule l'ann\u00e9e 2015 est pr\u00e9sente dans cette colonne."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2 : Pr\u00e9traitement-Repr\u00e9sentation\n",
        "\n",
        "*Effectuer un pr\u00e9traitement des donn\u00e9es pour supprimer les duplications et corriger les\n",
        "incoh\u00e9rences s\u2019il y en a.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Table `journal`\n",
        "\n",
        "On pourrait supposer que les ISSN permettent de d\u00e9finir une revue de fa\u00e7on unique, cependant, il existe de nombreuses\n",
        "lignes dupliqu\u00e9es qui poss\u00e8dent exactement les m\u00eames informations hormis leur ISSN. Il nous faut donc trouver un \n",
        "sous-ensemble de colonne qui nous permettrons de d\u00e9finir des duplicatas. \n",
        "\n",
        "Une deuxi\u00e8me hypoth\u00e8se que nous pouvons faire est qu'un journal est repr\u00e9sent\u00e9 par son nom et qu'il est peu probable que\n",
        "deux journaux diff\u00e9rents poss\u00e8de le m\u00eame nom. Nous allons donc consid\u00e9rer que deux lignes poss\u00e9dant le m\u00eame nom de\n",
        "journal sont des duplicatas. Pour diff\u00e9rencier deux deuplicatas nous allons ensuite calculer un poids correspondant au\n",
        "nombre de valeur non manquantes + 5 si la colonne `category` est non manquante. Ce choix de privil\u00e9gier la colonne\n",
        "`category` est fait de fa\u00e7on \u00e0 privil\u00e9gier les lignes avec cette colonne car elle sera importante pour les pr\u00e9dictions\n",
        "des questions suivantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Clean string columns\n",
        "journal[\"issn\"] = journal[\"issn\"].str.strip()\n",
        "journal[\"journal_name\"] = journal[\"journal_name\"].str.strip()\n",
        "journal[\"pub_name\"] = journal[\"pub_name\"].str.strip()\n",
        "journal[\"category\"] = journal[\"category\"].str.strip().str.lower()\n",
        "journal[\"url\"] = journal[\"url\"].str.strip()\n",
        "\n",
        "# remove duplicated values\n",
        "not_na_count = journal.notnull().sum(axis=1)\n",
        "row_to_keep = not_na_count.mask(journal[\"category\"].notna(), not_na_count+5).groupby(journal[\"journal_name\"]).idxmax()\n",
        "journal = journal.loc[row_to_keep]\n",
        "\n",
        "print(f\"Nombre de lignes cond\u00e9r\u00e9es comme dupliqu\u00e9es supprim\u00e9es : {not_na_count.shape[0] - row_to_keep.shape[0]}\")\n",
        "\n",
        "# Replace inconsistant seperators by one so that we can seperate the values easily later\n",
        "journal[\"category\"] = journal[\"category\"].str.replace(r\"\\s*([|.,&]|and)\\s*\", '|', regex=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Table `price`\n",
        "\n",
        "Cette table \u00e9tant une liste horodat\u00e9e de prix pour un journal, nous pouvons donc utiliser le couple des colonnes \n",
        "`date_stamp` et `journal_id` pour chercher les duplicatas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Clean string columns\n",
        "price[\"journal_id\"] = price[\"journal_id\"].str.strip()\n",
        "price[\"url\"] = price[\"url\"].str.strip()\n",
        "\n",
        "# Check duplicates\n",
        "price[price.duplicated(subset=[\"date_stamp\", \"journal_id\"]) & ~price.duplicated(subset=[\"date_stamp\", \"journal_id\", \"price\"])]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Seul un article poss\u00e8de un prix diff\u00e9rent pour la m\u00eame date (id `13073` et `16473`). En visitant le [site de la revue](https://jpl.letras.ulisboa.pt/about/submissions/)\n",
        "on peut trouver la mention de publiction fee de \u00a3330. On peut donc consid\u00e9rer la deuxi\u00e8me ligne avec un prix affich\u00e9 de\n",
        "$387.15 comme \u00e9tant la bonne ligne."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Delete the wrong article found\n",
        "price.drop(13073, inplace=True)\n",
        "\n",
        "# Delete the other duplicates\n",
        "price.drop_duplicates(subset=[\"date_stamp\", \"journal_id\"], inplace=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous avions aussi trouv\u00e9 une URL incoh\u00e9rente lors de la question 1 et l'avons d\u00e9j\u00e0 supprim\u00e9 \u00e0 ce moment l\u00e0.\n",
        "\n",
        "De plus, nous avions aussi trouv\u00e9 de tr\u00e8s nombreuses valeurs incoh\u00e9rentes dans la colonne `influence_id`. Par cons\u00e9quent,\n",
        "nous allons la supprimer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "price.drop(\"influence_id\", axis=1, inplace=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Table `influence`\n",
        "\n",
        "Pour cette table, \u00e0 l'instar de `journal`, nous ne pouvons pas nous baser sur la colonne ISSN car plusieurs lignes sont\n",
        "identiques si on exclu la v\u00e9rification de l'ISSN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# clean string columns\n",
        "influence[\"journal_name\"] = influence[\"journal_name\"].str.strip()\n",
        "influence[\"issn\"] = influence[\"issn\"].str.strip()\n",
        "\n",
        "# drop duplicates\n",
        "influence.drop_duplicates(subset=influence.drop(\"issn\", axis=1).columns, inplace=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalement, la colonne `url` \u00e9tant enti\u00e8rement vide, il nous semble inutile de la garder. De plus, la colonne\n",
        "`proj_ai_year` ne poss\u00e8de qu'une seule valeur non nulle, il nous semble donc peu utile de la garder aussi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "influence.drop(\"proj_ai_year\", axis=1, inplace=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Y a t il une corr\u00e9lation entre les cat\u00e9gories de journaux (attribut \u00ab category \u00bb) et les\n",
        "co\u00fbts de publication (attribut \u00ab price \u00bb) ? Justifier la r\u00e9ponse.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Afin d'obtenir une corr\u00e9lation plus pr\u00e9cise nous pouvons essayer de ne garder qu'une ligne pour chaque journal. Ce\n",
        "faisant nous gardons les prix les plus r\u00e9cent afin d'obtenir des statistiques plus \u00e0 jour."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# merge tables with the desired columns\n",
        "merge = journal.merge(price, left_on=\"issn\", right_on=\"journal_id\")\n",
        "\n",
        "# sort by date stamp\n",
        "merge.sort_values(by=[\"date_stamp\"], ascending=False, inplace=True)\n",
        "\n",
        "# only keep the first line of the duplicated journal name\n",
        "merge.drop_duplicates(subset=[\"journal_name\"], keep=\"first\", inplace=True)\n",
        "\n",
        "# drop unwanted columns\n",
        "merge.drop(merge.drop([\"category\", \"price\"], axis=1).columns, axis=1, inplace=True)\n",
        "\n",
        "# drop row where either the price or the category is missing\n",
        "merge.dropna(inplace=True)\n",
        "\n",
        "merge = pd.concat([merge, merge[\"category\"].str.get_dummies()], axis=1)\n",
        "\n",
        "correlations = []\n",
        "for col in merge.drop([\"category\", \"price\"], axis=1).columns:\n",
        "    group = merge[merge[col] == 1]\n",
        "    if group.shape[0] >= 10:    # filter out the category with not much data\n",
        "        correlations.append([col, group[\"price\"].values])\n",
        "\n",
        "# sort by prices' mean and extract values to list of cols and list of values\n",
        "correlations = list(zip(*sorted(correlations, key=lambda corr: corr[1].mean(), reverse=True)))\n",
        "\n",
        "sns.barplot(data=correlations[1])\n",
        "plt.xticks(plt.xticks()[0], labels=correlations[0], rotation=55, ha=\"right\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comme nous pouvons le voir sur le graphique ci-dessus, il semble que les cat\u00e9gories avec les prix les plus \u00e9lev\u00e9s soient\n",
        "semble \u00eatre li\u00e9 aux diff\u00e9rentes cat\u00e9gories des sciences (m\u00e9decine, biologie, phisique, chimie...). A contrario, il\n",
        "semble que les cat\u00e9gories avec les plus faibles prix soit tournent autours des arts, de la politique, de la lit\u00e9rature,\n",
        "de l'histoire...\n",
        "\n",
        "En r\u00e9sum\u00e9, nous pouvons dire que dans le cadre de nos donn\u00e9es il existe une corr\u00e9lation entre les colonnes `price` et\n",
        "`category`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Construire un mod\u00e8le pour pr\u00e9dire les valeurs de cat\u00e9gorie de journaux manquantes de\n",
        "la fa\u00e7on la plus pr\u00e9cise possible (cela inclut la s\u00e9lection d\u2019attributs informatifs, le\n",
        "choix et le param\u00e9trage d\u2019un mod\u00e8le de classification, le calcul du score du mod\u00e8le,\n",
        "l\u2019application du mod\u00e8le pour pr\u00e9dire les cat\u00e9gories manquantes). Justifier les choix\n",
        "effectu\u00e9s.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour pr\u00e9dire les valeurs des cat\u00e9gories nous allons utiliser les diff\u00e9rentes statistiques pr\u00e9sentes dans `influence` et\n",
        "les prix pr\u00e9sents dans `price`. Nous allons aussi calculer la distance entre les cat\u00e9gories et les deux premi\u00e8res\n",
        "colonnes de `journal` (`journal_name` et `pub_name`). Pour cette distance, nous allons calculer la longueur de la\n",
        "sous-chaine commune la plus longue et la diviser par la taille de la cat\u00e9gorie afin d'obtenir un \"pourcentage de\n",
        "ressemblance\".\n",
        "\n",
        "Pour le mod\u00e8le, nous allons utiliser un `MultiOutputClassifier` (pour pouvoir pr\u00e9dire plusieurs cat\u00e9gories \u00e0 un journal)\n",
        "avec un `RandomForestClassifier` (pour b\u00e9n\u00e9ficier de la capacit\u00e9 des arbres d\u00e9cisionnels et de leur simplicit\u00e9). Enfin,\n",
        "pour les hyper-param\u00e8tres, nous allons utiliser un `GridSearchCV`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# merge all data frames\n",
        "merge = journal.merge(price, left_on=\"issn\", right_on=\"journal_id\").merge(influence, on=\"issn\")\n",
        "merge.rename(columns={\"journal_name_x\": \"journal_name\"}, inplace=True)\n",
        "\n",
        "# drop unwanted columns\n",
        "desired_cols = [\"journal_name\", \"pub_name\", \"price\", \"citation_count_sum\", \"paper_count_sum\", \"avg_cites_per_paper\",\n",
        "                \"proj_ai\", \"category\"]\n",
        "cat_model_data = merge.drop(merge.drop(desired_cols, axis=1).columns, axis=1)\n",
        "\n",
        "# drop lines missing data used for prediction\n",
        "desired_cols.remove(\"category\") # we want to predict the missing categories at the end\n",
        "cat_model_data.dropna(subset=desired_cols, inplace=True)\n",
        "\n",
        "# compute training data targets\n",
        "train_mask = cat_model_data[\"category\"].notna()\n",
        "cat_targets = cat_model_data[train_mask][\"category\"].str.get_dummies(sep='|')\n",
        "cat_model_data.drop(\"category\", axis=1, inplace=True)\n",
        "\n",
        "# lower journal_name strings to make the string distance ignore cases\n",
        "cat_model_data[\"journal_name\"] = cat_model_data[\"journal_name\"].str.lower()\n",
        "\n",
        "# define the distance between a string (journal_name or pub_name) and a category\n",
        "def category_dist(row, base_col, category):\n",
        "    name = row[base_col]\n",
        "    if name is np.NaN:\n",
        "        return 0\n",
        "    len_match = SequenceMatcher(a=name, b=category).find_longest_match(0, len(name), 0, len(category)).size\n",
        "    return len_match / len(category)\n",
        "\n",
        "# compute the journal_name and pub_name distances with the categories for the data\n",
        "apply_category_dist = lambda df, base, cat: df.apply(category_dist, axis=1, base_col=base, category=cat)\n",
        "for category in tqdm(cat_targets.columns, desc=\"Computing distances between (journal_name, pub_name) and the categories\"):\n",
        "    cat_model_data[f\"journal_name_to_{category}_dist\"] = apply_category_dist(cat_model_data, \"journal_name\", category)\n",
        "    cat_model_data[f\"pub_name_to_{category}_dist\"] = apply_category_dist(cat_model_data, \"pub_name\", category)\n",
        "\n",
        "# drop string columns\n",
        "cat_model_data.drop([\"journal_name\", \"pub_name\"], axis=1, inplace=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# define the hyper-parameter's grid search\n",
        "param_grid = {\n",
        "    \"estimator__max_depth\" : np.linspace(13, 15, 3, dtype=int),\n",
        "    \"estimator__n_estimators\" : np.linspace(100, 200, 3, dtype=int)\n",
        "}\n",
        "\n",
        "# Create the model\n",
        "rfc = RandomForestClassifier(n_jobs=-1)\n",
        "moc = MultiOutputClassifier(rfc, n_jobs=-1)\n",
        "cat_model = GridSearchCV(moc, cv=2, param_grid=param_grid, n_jobs=-1, verbose=1)\n",
        "\n",
        "# Train model\n",
        "X_train, X_test, y_train, y_test = train_test_split(cat_model_data[train_mask], cat_targets, test_size=0.2)\n",
        "cat_model.fit(X_train, y_train)\n",
        "print(f\"Train accuracy : {cat_model.score(X_train, y_train):.2%}\")\n",
        "print(f\"Test  accuracy : {cat_model.score(X_test, y_test):.2%}\")\n",
        "print(f\"Best params : {cat_model.best_params_}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Predict missing categories\n",
        "predicted_cat = pd.DataFrame(cat_model.predict(cat_model_data), index=cat_model_data.index)\n",
        "\n",
        "# show stats about predicted data\n",
        "sns.barplot(data=predicted_cat.sum(axis=0))\n",
        "plt.xticks(plt.xticks()[0], labels=cat_targets.columns, rotation=55, ha=\"right\")\n",
        "plt.show()\n",
        "\n",
        "# replace line where the category in know by its representation in one hot\n",
        "predicted_cat.mask(train_mask, cat_targets, inplace=True, axis=0)\n",
        "\n",
        "# add the resulting data to the merge data\n",
        "predicted_cat.reindex(merge.index)\n",
        "predicted_cat.fillna(0.)    # these are the categories we could not predict because of missing data\n",
        "merge = pd.concat([merge, predicted_cat], axis=1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comme on peut le voir sur le graphique la r\u00e9partition des cat\u00e9gories pr\u00e9dites n'est pas consistante. On remarque en\n",
        "particulier `medecine` qui est bien plus pr\u00e9dite que le reste et certaines cat\u00e9gorie ne semble pas \u00eatre pr\u00e9dites une\n",
        "seule fois. Malgr\u00e9 cela, le mod\u00e8le obtient quand m\u00eame un bon score de g\u00e9n\u00e9ralisation / de test. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3 : R\u00e9gression-Clustering\n",
        "\n",
        "*Supprimer tous les attributs ayant plus de 50% de donn\u00e9es manquantes.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def drop_empty_columns(df, threshold=0.5):\n",
        "    df.drop(df.columns[(df.isna().sum() / df.shape[0]) > threshold], axis=1, inplace=True)\n",
        "\n",
        "for df in [journal, price, influence]:\n",
        "    drop_empty_columns(df)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Construire un mod\u00e8le pour pr\u00e9dire le co\u00fbt actuel de publication (attribut \u00ab price \u00bb) \u00e0\n",
        "partir des autres attributs (cela inclut la s\u00e9lection d\u2019attributs informatifs, le choix et le\n",
        "param\u00e9trage d\u2019un mod\u00e8le de r\u00e9gression, le calcul du score du mod\u00e8le, l\u2019application du\n",
        "mod\u00e8le pour pr\u00e9dire les co\u00fbts). Justifier les choix effectu\u00e9s.\n",
        "Lister les 10 revues qui s\u2019\u00e9cartent le plus (en + ou -) de la valeur pr\u00e9dite.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour calculer les co\u00fbts actuels de publication, nous allons encore une fois utiliser les diff\u00e9rents attributs de la\n",
        "table `influence` et de `price`. \u00c0 cela, nous allons aussi utiliser les cat\u00e9gories pr\u00e9sentent dans `category` que nous\n",
        "compl\u00e8teront avec le mod\u00e8le pr\u00e9c\u00e9demment entrain\u00e9.\n",
        "\n",
        "Pour le mod\u00e8le de regression, nous allons cette fois-ci utiliser un `RandomForestRegressor` avec un `GridSearchCV` pour\n",
        "la recherche des hyper-param\u00e8tres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# drop unwanted columns\n",
        "desired_cols = [\"citation_count_sum\", \"paper_count_sum\", \"avg_cites_per_paper\", \"proj_ai\", \"is_hybrid\", \"price\"] \\\n",
        "               + list(range(predicted_cat.shape[1])) # the one hots of the categories\n",
        "price_model_data = merge.drop(merge.drop(desired_cols, axis=1).columns, axis=1)\n",
        "\n",
        "# drop lines missing data used for prediction\n",
        "price_model_data.dropna(subset=desired_cols, inplace=True)\n",
        "\n",
        "# compute training data targets\n",
        "price_targets = price_model_data[\"price\"]\n",
        "price_model_data.drop(\"price\", axis=1, inplace=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# define the hyper-parameter's grid search\n",
        "param_grid = {\n",
        "    \"max_depth\" : np.linspace(13, 17, 5, dtype=int),\n",
        "    \"n_estimators\" : np.linspace(100, 200, 11, dtype=int)\n",
        "}\n",
        "\n",
        "# Create the model\n",
        "rfr = RandomForestRegressor(n_jobs=-1)\n",
        "price_model = GridSearchCV(rfr, cv=2, param_grid=param_grid, n_jobs=-1, verbose=1)\n",
        "\n",
        "# Train model\n",
        "X_train, X_test, y_train, y_test = train_test_split(price_model_data, price_targets, test_size=0.2)\n",
        "price_model.fit(X_train, y_train)\n",
        "print(f\"Train accuracy : {price_model.score(X_train, y_train):.2%}\")\n",
        "print(f\"Test  accuracy : {price_model.score(X_test, y_test):.2%}\")\n",
        "print(f\"Best params : {price_model.best_params_}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute the absolute price difference\n",
        "predicted_price = price_model.predict(price_model_data)\n",
        "predicted_price -= price_targets\n",
        "predicted_price = np.abs(predicted_price)\n",
        "predicted_price = pd.Series(predicted_price, index=price_model_data.index).sort_values(ascending=False)\n",
        "predicted_price = np.reshape(predicted_price, (-1, 1))\n",
        "\n",
        "# plot the first ten worst predictions\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "sns.barplot(x=merge[\"journal_name\"][predicted_price[:10].index], y=predicted_price[:10])\n",
        "plt.xticks(rotation=25, ha=\"right\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comme nous pouvons le constater sur le graphique ci-dessus, les 10 plus grandes erreurs de pr\u00e9dictions sont comprises\n",
        "entre 2000 et 3000 avec une exception pour la premi\u00e8re \u00e0 6000. Si on observe les donn\u00e9es, nous pouvons nous rendre\n",
        "compte que le premier journal fut pr\u00e9dit \u00e0 0 alors que le prix du journal \u00e9tait de 6000 et inversement, le prix du\n",
        "deuxi\u00e8me journal fut pr\u00e9dit \u00e0 3000 au lieu de 0. Nous pouvons donc conclure que notre mod\u00e8le est suffisement pr\u00e9cis pour\n",
        "pr\u00e9dir le prix moyen des journaux mais n'est pas encore capable d'identifier des *outliers* qui proposent des prix bien\n",
        "diff\u00e9rents des autres."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Construire un mod\u00e8le pour grouper les revues suivant le co\u00fbt actuel de publication\n",
        "(attribut \u00ab price \u00bb) et le score d\u2019influence (attribut \u00ab proj_ai \u00bb) (cela inclut la\n",
        "d\u00e9termination du nombre de clusters, le choix et le param\u00e9trage d\u2019un mod\u00e8le de\n",
        "clustering, l\u2019application du mod\u00e8le pour trouver les clusters). Justifier les choix\n",
        "effectu\u00e9s.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "clustering_data = merge[[\"proj_ai\", \"price\"]].dropna()\n",
        "sns.scatterplot(x=clustering_data[\"proj_ai\"], y=clustering_data[\"price\"])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Pr\u00e9senter des statistiques descriptives des clusters obtenus, et lister les revues du\n",
        "meilleur cluster en termes de rapport moyen : score d\u2019influence / co\u00fbt de publication.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}